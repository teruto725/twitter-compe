{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import emoji\n",
    "import jaconv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\井原輝人\\Desktop\\sorcecode\\twitter-compe\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特徴量の抽出\n",
    "def add_flags_nums(df):\n",
    "    #urlの有無\n",
    "    df[\"is_url\"] = df['text'].str.contains(r'(https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+)')\n",
    "    df[\"is_url\"] = (df[\"is_url\"]*1).astype(np.float64)\n",
    "    \n",
    "    #locationの有無\n",
    "    df[\"is_location\"] = df[\"location\"].isnull()\n",
    "    df[\"is_url\"] = (df[\"is_url\"]*1).astype(np.float64)\n",
    "    \n",
    "    #絵文字の個数\n",
    "    df[\"num_emoji\"] = np.zeros(len(df.index))\n",
    "    for idx in range(0,len(df.index)):\n",
    "        for letter in df[\"text\"].loc[idx]:\n",
    "            if letter in  emoji.EMOJI_UNICODE.values():\n",
    "                df[\"num_emoji\"].loc[idx] += 1\n",
    "    df[\"num_emoji\"] = df[\"num_emoji\"].astype(np.float64)    \n",
    "    \n",
    "    #リプライの数\n",
    "    df[\"num_reply\"] = df['text'].str.count('@').astype(np.float64)\n",
    "    \n",
    "    #ハッシュタグの数\n",
    "    df[\"num_hash\"] = df['text'].str.count('#').astype(np.float64)\n",
    "    \n",
    "    #テキストの長さ\n",
    "    df[\"text_length\"] = np.zeros(df.shape[0])\n",
    "    for idx in range(df.shape[0]):\n",
    "        df[\"text_length\"].loc[idx] = len(df[\"text\"].loc[idx])\n",
    "    df[\"text_length\"] = df[\"text_length\"].astype(np.float64)\n",
    "    \n",
    "    #生えてる草の個数\n",
    "    df[\"num_kusa\"] = df[\"text\"].str.count(\"w\")\n",
    "    df[\"num_kusa\"] = df[\"num_kusa\"].astype(np.float64)\n",
    "    \n",
    "    #日付が入っているか\n",
    "    df[\"is_date\"] = df['text'].str.contains(r'([0-9]日)')\n",
    "    df[\"is_date\"] = (df[\"is_date\"]*1).astype(np.float64)\n",
    "    df[\"is_time\"] = df['text'].str.contains(r'([0-9]時)')\n",
    "    df[\"is_time\"] = (df[\"is_time\"]*1).astype(np.float64)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テキストのクリーニング\n",
    "def cleaning(df):\n",
    "    #urlの削除\n",
    "    df[\"text\"] = df[\"text\"].replace(r'(https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+)',\"\",regex=True)\n",
    "    #replyの削除\n",
    "    df[\"text\"] = df[\"text\"].replace(r'@([A-Za-z0-9_])+',\"\",regex = True)\n",
    "    #全角スペースを半角スペースに\n",
    "    df[\"text\"] = jaconv.z2h(df[\"text\"].str,digit=True, ascii = True) \n",
    "    #大文字を小文字に\n",
    "    df[\"text\"] = df[\"text\"].str.lower()\n",
    "    #数字を0に置き換える\n",
    "    df[\"text\"] = df[\"text\"].replace(r'([0-9])',\"0\",regex = True)    \n",
    "    #アカウント名と思しきものを消す\n",
    "    ####\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分かち書き\n",
    "from janome.tokenizer import Tokenizer\n",
    "def wakati(df):\n",
    "    df[\"text_wakati\"] = str()\n",
    "    t= Tokenizer()\n",
    "\n",
    "    for idx in range(0,df.shape[0]):\n",
    "        df[\"text_wakati\"].loc[idx] = [token.base_form for token in t.tokenize(df[\"text\"].loc[idx])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1文字の単語を消す\n",
    "def del_one(df):\n",
    "    delonelist = list()\n",
    "    for i in range(df.shape[0]):\n",
    "        wakati = df[\"text_wakati\"].values[i]\n",
    "        del_one = \"\"\n",
    "        for idx in range(len(wakati)):\n",
    "            if len(str(wakati[idx])) > 1:\n",
    "                del_one += (wakati[idx]+\" \")\n",
    "        delonelist.append(np.array(del_one))\n",
    "    df[\"text_del_one\"] = np.array(delonelist)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\井原輝人\\desktop\\sorcecode\\twitter-compe\\venv\\lib\\site-packages\\pandas\\core\\strings.py:1952: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "c:\\users\\井原輝人\\desktop\\sorcecode\\twitter-compe\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#trainデータの読み込み\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "#train_df = train_df.head(100)\n",
    "train_df = add_flags_nums(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = cleaning(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = wakati(train_df)\n",
    "train_df = del_one(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"./arranged_data/train2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'flg', 'keyword', 'location', 'text', 'is_url', 'is_location',\n",
       "       'num_emoji', 'num_reply', 'num_hash', 'text_length', 'num_kusa',\n",
       "       'is_date', 'is_time', 'text_wakati', 'text_del_one'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_train = train_df[[\"is_url\",\"is_location\",\"num_emoji\",\"num_reply\",\"num_hash\",\"text_length\",\"num_kusa\",\"is_date\",\"is_time\",\"text_del_one\"]]\n",
    "Y_df_train = train_df[\"flg\"].astype(np.int64)\n",
    "X_train =  X_df_train.values\n",
    "y_train = Y_df_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_test = test_df[[\"is_url\",\"is_location\",\"num_emoji\",\"num_reply\",\"num_hash\",\"text_length\",\"num_kusa\",\"is_date\",\"is_time\",\"text_del_one\"]]\n",
    "\n",
    "X_test =  X_df_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "# トレーニング用データにCountVectorizerを適用\n",
    "X_train = cv.fit_transform(X_train[:,9])\n",
    "# バリデーション用データにCountVectorizerを適用\n",
    "X_test = cv.transform(X_test[:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=500,\n",
    "                                    random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score ,precision_score, recall_score,f1_score\n",
    "import seaborn as sns\n",
    "def result_heatmap(Y_test,Y_pred):\n",
    "    print(\"正解率:\"+str(accuracy_score(Y_test, Y_pred)))\n",
    "    print(\"適合率:\"+str(recall_score(Y_test,Y_pred)))\n",
    "    print(\"再現率:\"+str(precision_score(Y_test,Y_pred)))\n",
    "    print(\"F値:\"+str(f1_score(Y_test, Y_pred)))  \n",
    "    cm = confusion_matrix(Y_test, Y_pred)\n",
    "    sns.heatmap(cm,annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#普通にやると全部違う方に分類される\n",
    "y_pred = model.predict(X_test)\n",
    "ans_df=pd.DataFrame()\n",
    "ans_df[\"flg\"] = y_pred\n",
    "ans_df.to_csv(\"./data/ans_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\井原輝人\\desktop\\sorcecode\\twitter-compe\\venv\\lib\\site-packages\\pandas\\core\\strings.py:1952: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "c:\\users\\井原輝人\\desktop\\sorcecode\\twitter-compe\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "test_df = add_flags_nums(test_df)\n",
    "test_df = cleaning(test_df)\n",
    "test_df = wakati(test_df)\n",
    "test_df = del_one(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"./arranged_data/test2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
