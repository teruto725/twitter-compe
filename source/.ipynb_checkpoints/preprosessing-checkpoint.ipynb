{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import emoji\n",
    "import jaconv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\井原輝人\\Desktop\\sorcecode\\twitter-compe\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特徴量の抽出\n",
    "def add_flags_nums(df):\n",
    "    #urlの有無\n",
    "    df[\"is_url\"] = df['text'].str.contains(r'(https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+)')\n",
    "    df[\"is_url\"] = (df[\"is_url\"]*1).astype(np.float64)\n",
    "    \n",
    "    #locationの有無\n",
    "    df[\"is_location\"] = df[\"location\"].isnull()\n",
    "    df[\"is_url\"] = (df[\"is_url\"]*1).astype(np.float64)\n",
    "    \n",
    "    #絵文字の個数\n",
    "    df[\"num_emoji\"] = np.zeros(len(df.index))\n",
    "    for idx in range(0,len(df.index)):\n",
    "        for letter in df[\"text\"].loc[idx]:\n",
    "            if letter in  emoji.EMOJI_UNICODE.values():\n",
    "                df[\"num_emoji\"].loc[idx] += 1\n",
    "    df[\"num_emoji\"] = df[\"num_emoji\"].astype(np.float64)    \n",
    "    \n",
    "    #リプライの数\n",
    "    df[\"num_reply\"] = df['text'].str.count('@').astype(np.float64)\n",
    "    \n",
    "    #ハッシュタグの数\n",
    "    df[\"num_hash\"] = df['text'].str.count('#').astype(np.float64)\n",
    "    \n",
    "    #テキストの長さ\n",
    "    df[\"text_length\"] = np.zeros(df.shape[0])\n",
    "    for idx in range(df.shape[0]):\n",
    "        df[\"text_length\"].loc[idx] = len(df[\"text\"].loc[idx])\n",
    "    df[\"text_length\"] = df[\"text_length\"].astype(np.float64)\n",
    "    \n",
    "    #生えてる草の個数\n",
    "    df[\"num_kusa\"] = df[\"text\"].str.count(\"w\")\n",
    "    df[\"num_kusa\"] = df[\"num_kusa\"].astype(np.float64)\n",
    "    \n",
    "    #日付が入っているか\n",
    "    df[\"is_date\"] = df['text'].str.contains(r'([0-9]日)')\n",
    "    df[\"is_date\"] = (df[\"is_date\"]*1).astype(np.float64)\n",
    "    df[\"is_time\"] = df['text'].str.contains(r'([0-9]時)')\n",
    "    df[\"is_time\"] = (df[\"is_time\"]*1).astype(np.float64)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テキストのクリーニング\n",
    "def cleaning(df):\n",
    "    #urlの削除\n",
    "    df[\"text\"] = df[\"text\"].replace(r'(https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+)',\"\",regex=True)\n",
    "    #replyの削除\n",
    "    df[\"text\"] = df[\"text\"].replace(r'@([A-Za-z0-9_])+',\"\",regex = True)\n",
    "    #全角スペースを半角スペースに\n",
    "    df[\"text\"] = jaconv.z2h(df[\"text\"].str,digit=True, ascii = True) \n",
    "    #大文字を小文字に\n",
    "    df[\"text\"] = df[\"text\"].str.lower()\n",
    "    #数字を0に置き換える\n",
    "    df[\"text\"] = df[\"text\"].replace(r'([0-9])',\"0\",regex = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分かち書き\n",
    "from janome.tokenizer import Tokenizer\n",
    "def wakati(df):\n",
    "    df[\"text_wakati\"] = str()\n",
    "    t= Tokenizer()\n",
    "\n",
    "    for idx in range(0,df.shape[0]):\n",
    "        df[\"text_wakati\"].loc[idx] = [token.base_form for token in t.tokenize(df[\"text\"].loc[idx])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1文字の単語を消す\n",
    "def del_one(df):\n",
    "    delonelist = list()\n",
    "    for i in range(df.shape[0]):\n",
    "        wakati = df[\"text_wakati\"].values[i]\n",
    "        del_one = \"\"\n",
    "        for idx in range(len(wakati)):\n",
    "            if len(str(wakati[idx])) > 1:\n",
    "                del_one += (wakati[idx]+\" \")\n",
    "        delonelist.append(np.array(del_one))\n",
    "    df[\"text_del_one\"] = np.array(delonelist)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\井原輝人\\desktop\\sorcecode\\twitter-compe\\venv\\lib\\site-packages\\pandas\\core\\strings.py:1952: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "c:\\users\\井原輝人\\desktop\\sorcecode\\twitter-compe\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#trainデータの読み込み\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df = train_df.head(100)\n",
    "train_df = add_flags_nums(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = cleaning(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = wakati(train_df)\n",
    "train_df = del_one(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"./arranged_data/train2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ba56249184eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_flags_nums\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwakati\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdel_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-068fdac7714d>\u001b[0m in \u001b[0;36madd_flags_nums\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mletter\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0memoji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEMOJI_UNICODE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_emoji\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_emoji\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_emoji\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "test_df = add_flags_nums(test_df)\n",
    "test_df = cleaning(test_df)\n",
    "test_df = wakati(test_df)\n",
    "test_df = del_one(test_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.to_csv(\"./arranged_data/test2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
