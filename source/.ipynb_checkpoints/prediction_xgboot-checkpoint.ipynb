{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akite\\OneDrive\\デスクトップ\\source code\\twitter-compe\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/preprosessing_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_train = train_df[[\"is_url\",\"is_location\",\"num_emoji\",\"num_reply\",\"num_hash\",\"text_length\",\"num_kusa\",\"is_date\",\"is_time\",\"text_wakati\"]]\n",
    "Y_df_train = train_df[\"flg\"].astype(np.int64)\n",
    "X_train =  X_df_train.values\n",
    "y_train = Y_df_train.values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20285 entries, 0 to 20284\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   is_url       20285 non-null  float64\n",
      " 1   is_location  20285 non-null  float64\n",
      " 2   num_emoji    20285 non-null  float64\n",
      " 3   num_reply    20285 non-null  float64\n",
      " 4   num_hash     20285 non-null  float64\n",
      " 5   text_length  20285 non-null  float64\n",
      " 6   num_kusa     20285 non-null  float64\n",
      " 7   is_date      20285 non-null  float64\n",
      " 8   is_time      20285 non-null  float64\n",
      " 9   text_wakati  20285 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16228, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#特徴量配列\n",
    "X_train_feat = X_train[:,:8]\n",
    "X_valid_feat = X_valid[:,:8]\n",
    "X_train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特徴量標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "ss = MinMaxScaler()\n",
    "X_train_feat_ss = ss.fit_transform(X_train_feat)\n",
    "X_valid_feat_ss = ss.transform(X_valid_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文字カラムに対する欠損値削除\n",
    "X_train_del_one = X_train[:,9]\n",
    "for idx in range(len(X_train_del_one)):\n",
    "    if type(X_train_del_one[idx]) is float:\n",
    "        X_train_del_one[idx] = \" \" \n",
    "\n",
    "X_valid_del_one = X_valid[:,9]\n",
    "for idx in range(len(X_valid_del_one)):\n",
    "    if type(X_valid_del_one[idx]) is float:\n",
    "        X_valid_del_one[idx] = \" \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#単語ベクトル化(最大値、最小値を設定した)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "cv = TfidfVectorizer(min_df=10/16228, max_df=3000/16228)\n",
    "X_train_cv = cv.fit_transform(X_train_del_one)\n",
    "X_valid_cv = cv.transform(X_valid_del_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文字配列と特徴量の配列を結合する\n",
    "X_train = np.concatenate([X_train_cv.toarray(),X_train_feat_ss],1)\n",
    "X_valid = np.concatenate([X_valid_cv.toarray(),X_valid_feat_ss],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#型変換\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_valid = X_valid.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#スパース配列に変換\n",
    "from scipy.sparse import csr_matrix\n",
    "X_train_csr = csr_matrix(X_train)\n",
    "X_valid_csr = csr_matrix(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score ,precision_score, recall_score,f1_score\n",
    "import seaborn as sns\n",
    "def result_heatmap(Y_test,Y_pred):\n",
    "    print(\"正解率:\"+str(accuracy_score(Y_test, Y_pred)))\n",
    "    print(\"適合率:\"+str(recall_score(Y_test,Y_pred)))\n",
    "    print(\"再現率:\"+str(precision_score(Y_test,Y_pred)))\n",
    "    print(\"F値:\"+str(f1_score(Y_test, Y_pred)))  \n",
    "    cm = confusion_matrix(Y_test, Y_pred)\n",
    "    print(cm)\n",
    "    sns.heatmap(cm,annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/preprosessing_test.csv')\n",
    "X_df_test =  test_df[[\"is_url\",\"is_location\",\"num_emoji\",\"num_reply\",\"num_hash\",\"text_length\",\"num_kusa\",\"is_date\",\"is_time\",\"text_wakati\"]]\n",
    "X_test = X_df_test.values\n",
    "X_test_feat = X_test[:,:8]\n",
    "X_test_feat_ss = ss.transform(X_test_feat)\n",
    "X_test_del_one = X_test[:,9]\n",
    "for idx in range(len(X_test_del_one)):\n",
    "    if type(X_test_del_one[idx]) is float:\n",
    "        X_test_del_one[idx] = \" \" \n",
    "X_test_cv = cv.transform(X_test_del_one)\n",
    "print(X_test_cv.shape)\n",
    "X_test = np.concatenate([X_test_cv.toarray(),X_test_feat_ss],1)\n",
    "print(X_test.shape)\n",
    "X_test = X_test.astype(np.float64)\n",
    "X_test_csr = csr_matrix(X_test)\n",
    "print(X_test_csr.shape)\n",
    "y_pred_test = model.predict(X_test_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_valid_csr)\n",
    "result_heatmap(y_valid,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
